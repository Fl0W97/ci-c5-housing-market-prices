{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Cleaning Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "- Evaluate missing data\n",
    "- Clean data by converting data types, reduces the influence of extreme outliners, log transformation and box-cox / Yeo-Johnson transformation\n",
    "\n",
    "## Inputs\n",
    "- outputs/data_collection/house_price_data.csv\n",
    "\n",
    "## Outputs\n",
    "- Generate Dataset: outputs/cleaning/house_prive_data_cleaned.csv\n",
    "\n",
    "## Conclusion\n",
    "- Data cleaning pipeline\n",
    "- Drop Variables: ['EnclosedPorch', 'WoodDeckSF', 'BsmtFinType1', 'LotArea', 'BsmtUnfSF', 'BedroomAbvGr', 'BsmtExposure', 'OverallCond']\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to change the working directory from its current folder to its parent folder\n",
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load collected and analysed data from outputs/collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>...</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856</td>\n",
       "      <td>854.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>706</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>548</td>\n",
       "      <td>RFn</td>\n",
       "      <td>...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>978</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>460</td>\n",
       "      <td>RFn</td>\n",
       "      <td>...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>920</td>\n",
       "      <td>866.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Mn</td>\n",
       "      <td>486</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>608</td>\n",
       "      <td>RFn</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  BedroomAbvGr BsmtExposure  BsmtFinSF1 BsmtFinType1  \\\n",
       "0       856     854.0           3.0           No         706          GLQ   \n",
       "1      1262       0.0           3.0           Gd         978          ALQ   \n",
       "2       920     866.0           3.0           Mn         486          GLQ   \n",
       "\n",
       "   BsmtUnfSF  EnclosedPorch  GarageArea GarageFinish  ...  LotFrontage  \\\n",
       "0        150            0.0         548          RFn  ...         65.0   \n",
       "1        284            NaN         460          RFn  ...         80.0   \n",
       "2        434            0.0         608          RFn  ...         68.0   \n",
       "\n",
       "   MasVnrArea OpenPorchSF  OverallCond  OverallQual  TotalBsmtSF  WoodDeckSF  \\\n",
       "0       196.0          61            5            7          856         0.0   \n",
       "1         0.0           0            8            6         1262         NaN   \n",
       "2       162.0          42            5            7          920         NaN   \n",
       "\n",
       "   YearBuilt  YearRemodAdd  SalePrice  \n",
       "0       2003          2003     208500  \n",
       "1       1976          1976     181500  \n",
       "2       2001          2002     223500  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_raw_path = \"outputs/data_collected/house_pricing_data.csv\"\n",
    "df = pd.read_csv(df_raw_path)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some missing data. For cleaning it the function DataCleaningEffect() is used (from feature-engine lession)\n",
    "\n",
    "a. Drop Columns:\n",
    "If a column has a very high proportion of missing data (like EnclosedPorch and WoodDeckSF), it may be best to drop the column altogether. As well as for LotFrontage (259 missing).\n",
    "\n",
    "b. Impute Missing Values:\n",
    "For columns with a moderate amount of missing data, imputation is a good strategy. There are different methods for imputing based on the nature of the data\n",
    "\n",
    "- For numeric columns (e.g., 2ndFlrSF, BedroomAbvGr, BsmtExposure, GarageYrBlt): You can impute the missing values using the mean, median, or mode (depending on the distribution of the data). The median is often a good choice for columns with skewed distributions or outliers.\n",
    "- For categorical columns (e.g., BsmtExposure, BsmtFinType1, GarageFinish): Impute the missing values with the mode (most frequent value) since these are categorical variables.\n",
    "- For columns like MasVnrArea (small number of missing values): Since MasVnrArea has only 8 missing values, impute using the mean or median, or even consider using the mode depending on the column’s nature. If the percentage is very small, drop rows with missing values in some cases.\n",
    "- For GarageYrBlt (81 missing): An imputation with with the mode or mean of the year values is not useful. Using a more sophisticated method, like predictive modeling or filling based on group statistics (e.g., grouping by the presence of a garage) is better.\n",
    "\n",
    "c. Fill Missing with Specific Values:\n",
    "For certain categorical columns, you might want to fill missing values with a specific placeholder like 'Unknown' or 'None' if that's a valid way to handle missing data for that variable.\n",
    "\n",
    "\n",
    "By using a machine learning model, more sophisticated imputation techniques can be used, such as:\n",
    "\n",
    "- K-Nearest Neighbors (KNN) imputation: Uses the values of the closest data points to impute missing values.\n",
    "- Regression-based imputation: You can use a regression model to predict missing values based on other features in the dataset.\n",
    "\n",
    "\n",
    "Current approach:\n",
    "- Drop columns with a very high percentage of missing values (e.g., EnclosedPorch, WoodDeckSF)\n",
    "- Impute missing values for columns with moderate missing data:\n",
    "  - Numeric columns (e.g., 2ndFlrSF, BedroomAbvGr) using the mean, median, or mode.\n",
    "  - Categorical columns (e.g., BsmtExposure, BsmtFinType1) using the mode (most frequent value).\n",
    "-  For small missing data counts (e.g., MasVnrArea), impute with the mean or median.\n",
    "\n",
    "Considering model-based imputation for more advanced techniques (MERIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following varibales will be dropped because the number of missing values is too high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['EnclosedPorch', 'WoodDeckSF'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric columns:\n",
    "df['2ndFlrSF'] = df['2ndFlrSF'].fillna(df['2ndFlrSF'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical columns\n",
    "df['GarageFinish'] = df['GarageFinish'].fillna(df['GarageFinish'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#small number of missing values\n",
    "df['MasVnrArea'] = df['MasVnrArea'].fillna(df['MasVnrArea'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Duplicates (no duplicates has been found)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Incorrect Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the data inspectation the conclusion was that ['BsmtExposure', 'BsmtFinType1', 'GarageFinish', 'KitchenQual'] have the wrong data type. Here it is adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Convert the columns to string type (it will handle NaN as 'nan' string)\n",
    "df['BsmtExposure'] = df['BsmtExposure'].astype(str)\n",
    "df['BsmtFinType1'] = df['BsmtFinType1'].astype(str)\n",
    "df['GarageFinish'] = df['GarageFinish'].astype(str)\n",
    "df['KitchenQual'] = df['KitchenQual'].astype(str)\n",
    "\n",
    "# Step 2: Strip any leading/trailing whitespace from the column values\n",
    "df['BsmtExposure'] = df['BsmtExposure'].str.strip()\n",
    "df['BsmtFinType1'] = df['BsmtFinType1'].str.strip()\n",
    "df['GarageFinish'] = df['GarageFinish'].str.strip()\n",
    "df['KitchenQual'] = df['KitchenQual'].str.strip()\n",
    "\n",
    "# Step 3: Replace string representation of 'NaN' with 'Unknown'\n",
    "df['BsmtExposure'] = df['BsmtExposure'].replace(\"nan\", \"Unknown\")\n",
    "df['BsmtFinType1'] = df['BsmtFinType1'].replace(\"nan\", \"Unknown\")\n",
    "df['GarageFinish'] = df['GarageFinish'].replace(\"nan\", \"Unknown\")\n",
    "df['KitchenQual'] = df['KitchenQual'].replace(\"nan\", \"Unknown\")\n",
    "\n",
    "# Step 4: Map categorical values to numeric\n",
    "df['BsmtExposure'] = df['BsmtExposure'].replace({\n",
    "    \"No\": 0,\n",
    "    \"Gd\": 1,\n",
    "    \"Mn\": 2,\n",
    "    \"Av\": 3,\n",
    "    \"Ex\": 4,\n",
    "    \"Unknown\": np.nan  # Replace 'Unknown' with NaN for numerical operations\n",
    "})\n",
    "\n",
    "df['BsmtFinType1'] = df['BsmtFinType1'].replace({\n",
    "    \"GLQ\": 6,  # Good Living Quarters\n",
    "    \"ALQ\": 5,  # Average Living Quarters\n",
    "    \"BLQ\": 4,  # Below Average Living Quarters\n",
    "    \"Rec\": 3,  # Average Rec Room\n",
    "    \"LwQ\": 2,  # Low Quality\n",
    "    \"Unf\": 1,  # Unfinished\n",
    "    \"None\": 0  # No Basement\n",
    "})\n",
    "\n",
    "df['GarageFinish'] = df['GarageFinish'].replace({\n",
    "    \"Fin\": 3,  # Finished\n",
    "    \"RFn\": 2,  # Rough Finished\n",
    "    \"Unf\": 1,  # Unfinished\n",
    "    \"None\": 0  # No Garage\n",
    "})\n",
    "\n",
    "df['KitchenQual'] = df['KitchenQual'].replace({\n",
    "    \"Ex\": 4,  # Excellent\n",
    "    \"Gd\": 3,  # Good\n",
    "    \"TA\": 2,  # Typical/Average\n",
    "    \"Fa\": 1,  # Fair\n",
    "    \"Po\": 0   # Poor\n",
    "})\n",
    "\n",
    "\n",
    "# Step 5: Check the unique values to confirm that the columns contain only valid values\n",
    "print(\"Unique values in BsmtExposure:\", df['BsmtExposure'].unique())\n",
    "print(\"Unique values in BsmtFinType1:\", df['BsmtFinType1'].unique())\n",
    "print(\"Unique values in GarageFinish:\", df['GarageFinish'].unique())\n",
    "print(\"Unique values in KitchenQual:\", df['KitchenQual'].unique())\n",
    "\n",
    "# Step 6: Apply numeric conversion safely (handle non-numeric values)\n",
    "df['BsmtExposure'] = pd.to_numeric(df['BsmtExposure'], errors='coerce')\n",
    "df['BsmtFinType1'] = pd.to_numeric(df['BsmtFinType1'], errors='coerce')\n",
    "df['GarageFinish'] = pd.to_numeric(df['GarageFinish'], errors='coerce')\n",
    "df['KitchenQual'] = pd.to_numeric(df['KitchenQual'], errors='coerce')\n",
    "\n",
    "# Step 7: Check the first few rows to ensure the transformation worked\n",
    "print(df.head())\n",
    "\n",
    "# Step 8: Calculate the correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcting Outliers (tbd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with reults of the correlation analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following varibales will be dropped because the corrlation values are low and irrelevant for the further process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['BsmtFinType1', 'LotArea', 'BsmtUnfSF', 'BedroomAbvGr', 'BsmtExposure', 'OverallCond'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find here the data cleaning approaches:\n",
    "\n",
    "- Drop the following parameters because those have a low impact on the sales price \n",
    "['BsmtFinType1', 'LotArea', 'WoodDeckSF', 'BsmtUnfSF', 'BedroomAbvGr', 'BsmtExposure', 'OverallCond', 'EnclosedPorch']\n",
    "\n",
    "- Drop variables with more then 80% of missing data since these varables wil likely not add much value\n",
    "['WoodDeckSF', 'EnclosedPorch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push cleaned data to Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "  os.makedirs(name='outputs/data_cleaned') # create outputs/data_cleaned folder\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Test and Train data\n",
    "Splitting Data: Typically, you split your dataset into train and test sets. For instance:\n",
    "\n",
    "`A common split is 70% for training and 30% for testing (though this can vary based on the problem and dataset size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into train and test sets\n",
    "TrainSet, TestSet = train_test_split(df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(\"outputs/data_cleaned\", exist_ok=True)\n",
    "\n",
    "# Save the DataFrame to CSV\n",
    "TrainSet.to_csv(\"outputs/data_cleaned/TrainSet.csv\", index=False)\n",
    "\n",
    "print(TrainSet.head(10))  # Display the first 10 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(\"outputs/data_cleaned\", exist_ok=True)\n",
    "\n",
    "# Save the DataFrame to CSV\n",
    "TestSet.to_csv(\"outputs/data_cleaned/TestSet.csv\", index=False)\n",
    "\n",
    "print(TestSet.head(10))  # Display the first 10 rows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
